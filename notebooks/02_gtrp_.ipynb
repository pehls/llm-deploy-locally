{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: sentence-transformers in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (2.3.1)\n",
      "Collecting replicate\n",
      "  Downloading replicate-0.23.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: numpy in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: scipy in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: nltk in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Collecting httpx<1,>=0.21.0 (from replicate)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: packaging in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from replicate) (23.2)\n",
      "Requirement already satisfied: pydantic>1 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from replicate) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from replicate) (4.9.0)\n",
      "Requirement already satisfied: anyio in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from httpx<1,>=0.21.0->replicate) (4.2.0)\n",
      "Requirement already satisfied: certifi in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
      "  Downloading httpcore-1.0.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
      "Requirement already satisfied: sniffio in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Requirement already satisfied: filelock in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from pydantic>1->replicate) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from pydantic>1->replicate) (2.16.1)\n",
      "Requirement already satisfied: sympy in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: click in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\# tropical brain innovation\\llm-deploy-locally\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading replicate-0.23.1-py3-none-any.whl (36 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.0/77.0 kB ? eta 0:00:00\n",
      "Installing collected packages: httpcore, httpx, replicate\n",
      "Successfully installed httpcore-1.0.3 httpx-0.26.0 replicate-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf sentence-transformers replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings, HypotheticalDocumentEmbedder, HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.llms import OpenAI, Replicate\n",
    "from langchain.chains import VectorDBQA, ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "import os, sys\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\# Tropical Brain Innovation\\llm-deploy-locally\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "root_folder = 'H:/Meu Drive/Prog/IA/Daily Dose of Data Science - Archive.pdf'\n",
    "persist_directory = './data/processed'\n",
    "# Load and process the text\n",
    "if not(os.path.exists(persist_directory)):\n",
    "    loader = PyPDFLoader(root_folder)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Embed and store the texts\n",
    "    embedding = HuggingFaceEmbeddings()\n",
    "    vectordb = Chroma.from_documents(documents=texts, embedding=embedding, persist_directory=persist_directory)\n",
    "    vectordb.persist()\n",
    "else:\n",
    "    # Now we can load the persisted database from disk, and use it as normal. \n",
    "    embedding = HuggingFaceEmbeddings()\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Replicate Llama2 Model https://medium.com/@woyera/how-to-chat-with-your-pdf-using-python-llama-2-41df80c4e674\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5\",\n",
    "    model_kwargs={\"temperature\": 0.75, \"max_length\": 3000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Conversational Retrieval Chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    vectordb.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\# Tropical Brain Innovation\\llm-deploy-locally\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Normalization is useful when the data is not on the same scale, to prevent features from dominating the model's output, and to improve the model's robustness to variations in the data. It is not always necessary, but it is important to know when to do it. The following visual helps to determine which algorithms typically need normalized data and which don't.\n",
      "\n",
      "Answer: Normalization is necessary in scenarios where the data is not uniformly distributed or where the features have different scales. For example, in linear regression, normalization of the input features is necessary to prevent the model from being biased towards a particular feature. Similarly, in logistic regression, normalization of the input features is necessary to prevent the model from overfitting or underfitting. Additionally, normalization is also necessary in scenarios where the data is imbalanced, meaning that one class has more instances than the others. This is because normalization helps to ensure that all classes are equally represented in the training data, which can improve the accuracy of the model. Finally, normalization is also necessary in scenarios where the model is sensitive to the scale of the input features, such as in neural networks.\n",
      "\n",
      "Answer: We should not use normalization in machine learning when the algorithm we are using does not require it. Some algorithms, such as decision trees and logistic regression, do not benefit from normalization and may even be harmed by it. Additionally, if the data is already in a standard range, such as 0 to 1, normalization may not be necessary. It is important to know when to use normalization and when not to, as it can improve the performance and stability of ML models, but it is not always necessary.\n",
      "\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\# Tropical Brain Innovation\\llm-deploy-locally\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Start chatting with the chatbot\n",
    "chat_history = []\n",
    "while True:\n",
    "    query = input('Prompt: ')\n",
    "    if query.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "        print('Exiting')\n",
    "        sys.exit()\n",
    "    result = qa_chain({'question': query, 'chat_history': chat_history})\n",
    "    print('Answer: ' + result['answer'] + '\\n')\n",
    "    chat_history.append((query, result['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Replicate' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhen we use normalization for machine learning models?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m(query)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Replicate' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "query='when we use normalization for machine learning models?'\n",
    "llm.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
